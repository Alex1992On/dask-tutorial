








<!DOCTYPE html>
<html lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Arrays &mdash; Dask Tutorial  documentation</title>
  

  
  
  
  

  
  <link rel="stylesheet" href="_static/css/style.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/explore.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/nbsphinx.css" type="text/css" />

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
        <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
        <script src="_static/js/custom.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Dask DataFrames" href="04_dataframe.html" />
    <link rel="prev" title="Bag: Parallel Lists for semi-structured data" href="02_bag.html" />
    <link rel="shortcut icon" href="_static/images/favicon.ico"/>
  
</head>

<body class="wy-body-for-nav">

  
    <nav id="explore-links">
        <a href="https://docs.dask.org/">
        <img class="caption" src="_static/images/dask-horizontal-white.svg"/>
        </a>

        <ul>
        <li>
            <a>Get Started</a>
            <ul>
            <li><a href="https://docs.dask.org/en/latest/install.html"> Install </a></li>
            <li><a href="https://examples.dask.org"> Examples </a></li>
            <li><a href="https://github.com/dask/dask-tutorial"> Tutorial </a></li>
            <li><a href="https://docs.dask.org/en/latest/why.html"> Why Dask? </a></li>
            <li><a href="https://stories.dask.org/en/latest"> Use Cases </a></li>
            <li><a href="https://www.youtube.com/watch?v=RA_2qdipVng&list=PLRtz5iA93T4PQvWuoMnIyEIz1fXiJ5Pri"> Talks </a></li>
            <li><a href="https://mybinder.org/v2/gh/dask/dask-examples/master?urlpath=lab"> Try Online </a></li>
            <li><a href="https://dask.org/slides"> Slides </a></li>
            </ul>
        </li>

        <li>
            <a href="">Algorithms</a>
            <ul>
            <li><a href="https://docs.dask.org/en/latest/array.html">Arrays</a></li>
            <li><a href="https://docs.dask.org/en/latest/dataframe.html">Dataframes</a></li>
            <li><a href="https://docs.dask.org/en/latest/bag.html">Bags</a></li>
            <li><a href="https://docs.dask.org/en/latest/delayed.html">Delayed (custom)</a></li>
            <li><a href="https://docs.dask.org/en/latest/futures.html">Futures (real-time)</a></li>
            <li><a href="http://ml.dask.org">Machine Learning</a></li>
            <li><a href="https://xarray.pydata.org/en/latest/">XArray</a></li>
            </ul>
        </li>

        <li>
            <a href="https://docs.dask.org/en/latest/setup.html">Setup</a>
            <ul>
            <li><a href="https://docs.dask.org/en/latest/setup/single-machine.html"> Local </a></li>
            <li><a href="https://docs.dask.org/en/latest/setup/cloud.html"> Cloud </a></li>
            <li><a href="https://docs.dask.org/en/latest/setup/hpc.html"> HPC </a></li>
            <li><a href="https://kubernetes.dask.org/en/latest/"> Kubernetes </a></li>
            <li><a href="https://yarn.dask.org/en/latest/"> Hadoop / Yarn </a></li>
            </ul>
        </li>

        <li>
            <a>Community</a>
            <ul>
            <li><a href="http://docs.dask.org/en/latest/support.html">Ask for Help</a></li>
            <li><a href="https://github.com/dask">Github</a></li>
            <li><a href="https://stackoverflow.com/questions/tagged/dask">Stack Overflow</a></li>
            <li><a href="https://twitter.com/dask_dev">Twitter</a></li>
            <li><a href="https://blog.dask.org/"> Developer Blog </a></li>
            </ul>
        </li>
        </ul>

    </nav>
  
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home" alt="Documentation Home"> Dask Tutorial
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="00_overview.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="01_dask.delayed.html">Parallelize code with <code class="docutils literal notranslate"><span class="pre">dask.delayed</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="01x_lazy.html">Lazy execution</a></li>
<li class="toctree-l1"><a class="reference internal" href="02_bag.html">Bag: Parallel Lists for semi-structured data</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Arrays</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#Create-data">Create data</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Setup">Setup</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Blocked-Algorithms">Blocked Algorithms</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Exercise:-Compute-the-mean-using-a-blocked-algorithm">Exercise: Compute the mean using a blocked algorithm</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#dask.array-contains-these-algorithms"><code class="docutils literal notranslate"><span class="pre">dask.array</span></code> contains these algorithms</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Exercise:-Compute-the-mean">Exercise: Compute the mean</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Performance-and-Parallelism">Performance and Parallelism</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Example">Example</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Performance-comparision">Performance comparision</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Exercise:-Meteorological-data">Exercise: Meteorological data</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Exercise:-Subsample-and-store">Exercise: Subsample and store</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Example:-Lennard-Jones-potential">Example: Lennard-Jones potential</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Dask-version">Dask version</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Limitations">Limitations</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="04_dataframe.html">Dask DataFrames</a></li>
<li class="toctree-l1"><a class="reference internal" href="05_distributed.html">Distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="06_distributed_advanced.html">Distributed, Advanced</a></li>
<li class="toctree-l1"><a class="reference internal" href="07_dataframe_storage.html">Data Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="08_machine_learning.html">Parallel and Distributed Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="08_machine_learning.html#Training-on-Large-Datasets">Training on Large Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="Homework.html">Homework</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Dask Tutorial</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Arrays</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/03_array.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container,
div.nbinput.container div.prompt,
div.nbinput.container div.input_area,
div.nbinput.container div[class*=highlight],
div.nbinput.container div[class*=highlight] pre,
div.nboutput.container,
div.nboutput.container div.prompt,
div.nboutput.container div.output_area,
div.nboutput.container div[class*=highlight],
div.nboutput.container div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    background: #f5f5f5;
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<p>You can run this notebook in a <a class="reference external" href="https://mybinder.org/v2/gh/dask/dask-tutorial/master?urlpath=lab/tree/03_array.ipynb">live session</a> <a class="reference external" href="https://mybinder.org/v2/gh/dask/dask-tutorial/master?urlpath=lab/tree/03_array.ipynb"><img alt="Binder" src="https://mybinder.org/badge.svg" /></a> or view it <a class="reference external" href="https://github.com/dask/dask-tutorial/blob/master/03_array.ipynb">on Github</a>.</p>
<p><a class="reference internal" href="_images/dask_horizontal.svg"><img alt="a0ba248975a8400e94f01fb9df13c816" src="_images/dask_horizontal.svg" width="30%" /></a></p>
<div class="section" id="Arrays">
<h1>Arrays<a class="headerlink" href="#Arrays" title="Permalink to this headline">¶</a></h1>
<p><a class="reference internal" href="_images/array.png"><img alt="7f7d13a8f9664ee4abcc5b694cb35009" src="_images/array.png" style="width: 25%;" /></a> Dask array provides a parallel, larger-than-memory, n-dimensional array using blocked algorithms. Simply put: distributed Numpy.</p>
<ul class="simple">
<li><p><strong>Parallel</strong>: Uses all of the cores on your computer</p></li>
<li><p><strong>Larger-than-memory</strong>: Lets you work on datasets that are larger than your available memory by breaking up your array into many small pieces, operating on those pieces in an order that minimizes the memory footprint of your computation, and effectively streaming data from disk.</p></li>
<li><p><strong>Blocked Algorithms</strong>: Perform large computations by performing many smaller computations</p></li>
</ul>
<p>In this notebook, we’ll build some understanding by implementing some blocked algorithms from scratch. We’ll then use Dask Array to analyze large datasets, in parallel, using a familiar NumPy-like API.</p>
<p><strong>Related Documentation</strong></p>
<ul class="simple">
<li><p><a class="reference external" href="https://docs.dask.org/en/latest/array.html">Array documentation</a></p></li>
<li><p><a class="reference external" href="https://youtu.be/9h_61hXCDuI">Array screencast</a></p></li>
<li><p><a class="reference external" href="https://docs.dask.org/en/latest/array-api.html">Array API</a></p></li>
<li><p><a class="reference external" href="https://examples.dask.org/array.html">Array examples</a></p></li>
</ul>
<div class="section" id="Create-data">
<h2>Create data<a class="headerlink" href="#Create-data" title="Permalink to this headline">¶</a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">%</span><span class="k">run</span> prep.py -d random
</pre></div>
</div>
</div>
</div>
<div class="section" id="Setup">
<h2>Setup<a class="headerlink" href="#Setup" title="Permalink to this headline">¶</a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">dask.distributed</span> <span class="kn">import</span> <span class="n">Client</span>

<span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="n">n_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">processes</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Blocked-Algorithms">
<h2>Blocked Algorithms<a class="headerlink" href="#Blocked-Algorithms" title="Permalink to this headline">¶</a></h2>
<p>A <em>blocked algorithm</em> executes on a large dataset by breaking it up into many small blocks.</p>
<p>For example, consider taking the sum of a billion numbers. We might instead break up the array into 1,000 chunks, each of size 1,000,000, take the sum of each chunk, and then take the sum of the intermediate sums.</p>
<p>We achieve the intended result (one sum on one billion numbers) by performing many smaller results (one thousand sums on one million numbers each, followed by another sum of a thousand numbers.)</p>
<p>We do exactly this with Python and NumPy in the following example:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Load data with h5py</span>
<span class="c1"># this creates a pointer to the data, but does not actually load</span>
<span class="kn">import</span> <span class="nn">h5py</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="s1">&#39;random.hdf5&#39;</span><span class="p">),</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="n">dset</span> <span class="o">=</span> <span class="n">f</span><span class="p">[</span><span class="s1">&#39;/x&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<p><strong>Compute sum using blocked algorithm</strong></p>
<p>Before using dask, lets consider the concept of blocked algorithms. We can compute the sum of a large number of elements by loading them chunk-by-chunk, and keeping a running total.</p>
<p>Here we compute the sum of this large array on disk by</p>
<ol class="arabic simple">
<li><p>Computing the sum of each 1,000,000 sized chunk of the array</p></li>
<li><p>Computing the sum of the 1,000 intermediate sums</p></li>
</ol>
<p>Note that this is a sequential process in the notebook kernel, both the loading and summing.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Compute sum of large array, one million numbers at a time</span>
<span class="n">sums</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1000000000</span><span class="p">,</span> <span class="mi">1000000</span><span class="p">):</span>
    <span class="n">chunk</span> <span class="o">=</span> <span class="n">dset</span><span class="p">[</span><span class="n">i</span><span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1000000</span><span class="p">]</span>  <span class="c1"># pull out numpy array</span>
    <span class="n">sums</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">chunk</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>

<span class="n">total</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">sums</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">total</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
4996558.75
</pre></div></div>
</div>
<div class="section" id="Exercise:-Compute-the-mean-using-a-blocked-algorithm">
<h3>Exercise: Compute the mean using a blocked algorithm<a class="headerlink" href="#Exercise:-Compute-the-mean-using-a-blocked-algorithm" title="Permalink to this headline">¶</a></h3>
<p>Now that we’ve seen the simple example above try doing a slightly more complicated problem, compute the mean of the array, assuming for a moment that we don’t happen to already know how many elements are in the data. You can do this by changing the code above with the following alterations:</p>
<ol class="arabic simple">
<li><p>Compute the sum of each block</p></li>
<li><p>Compute the length of each block</p></li>
<li><p>Compute the sum of the 1,000 intermediate sums and the sum of the 1,000 intermediate lengths and divide one by the other</p></li>
</ol>
<p>This approach is overkill for our case but does nicely generalize if we don’t know the size of the array or individual blocks beforehand.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Compute the mean of the array</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">sums</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">lengths</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1000000000</span><span class="p">,</span> <span class="mi">1000000</span><span class="p">):</span>
    <span class="n">chunk</span> <span class="o">=</span> <span class="n">dset</span><span class="p">[</span><span class="n">i</span><span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1000000</span><span class="p">]</span>  <span class="c1"># pull out numpy array</span>
    <span class="n">sums</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">chunk</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
    <span class="n">lengths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">chunk</span><span class="p">))</span>

<span class="n">total</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">sums</span><span class="p">)</span>
<span class="n">length</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">lengths</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">total</span> <span class="o">/</span> <span class="n">length</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
0.99931175
</pre></div></div>
</div>
</div>
</div>
<div class="section" id="dask.array-contains-these-algorithms">
<h2><code class="docutils literal notranslate"><span class="pre">dask.array</span></code> contains these algorithms<a class="headerlink" href="#dask.array-contains-these-algorithms" title="Permalink to this headline">¶</a></h2>
<p>Dask.array is a NumPy-like library that does these kinds of tricks to operate on large datasets that don’t fit into memory. It extends beyond the linear problems discussed above to full N-Dimensional algorithms and a decent subset of the NumPy interface.</p>
<p><strong>Create ``dask.array`` object</strong></p>
<p>You can create a <code class="docutils literal notranslate"><span class="pre">dask.array</span></code> <code class="docutils literal notranslate"><span class="pre">Array</span></code> object with the <code class="docutils literal notranslate"><span class="pre">da.from_array</span></code> function. This function accepts</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">data</span></code>: Any object that supports NumPy slicing, like <code class="docutils literal notranslate"><span class="pre">dset</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">chunks</span></code>: A chunk size to tell us how to block up our array, like <code class="docutils literal notranslate"><span class="pre">(1000000,)</span></code></p></li>
</ol>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">dask.array</span> <span class="k">as</span> <span class="nn">da</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">da</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">dset</span><span class="p">,</span> <span class="n">chunks</span><span class="o">=</span><span class="p">(</span><span class="mi">1000000</span><span class="p">,))</span>
<span class="n">x</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<table>
<tr>
<td>
<table>
  <thead>
    <tr><td> </td><th> Array </th><th> Chunk </th></tr>
  </thead>
  <tbody>
    <tr><th> Bytes </th><td> 20.00 MB </td> <td> 4.00 MB </td></tr>
    <tr><th> Shape </th><td> (5000000,) </td> <td> (1000000,) </td></tr>
    <tr><th> Count </th><td> 6 Tasks </td><td> 5 Chunks </td></tr>
    <tr><th> Type </th><td> float32 </td><td> numpy.ndarray </td></tr>
  </tbody>
</table>
</td>
<td>
<svg width="170" height="75" style="stroke:rgb(0,0,0);stroke-width:1" >

  <!-- Horizontal lines -->
  <line x1="0" y1="0" x2="120" y2="0" style="stroke-width:2" />
  <line x1="0" y1="25" x2="120" y2="25" style="stroke-width:2" />

  <!-- Vertical lines -->
  <line x1="0" y1="0" x2="0" y2="25" style="stroke-width:2" />
  <line x1="24" y1="0" x2="24" y2="25" />
  <line x1="48" y1="0" x2="48" y2="25" />
  <line x1="72" y1="0" x2="72" y2="25" />
  <line x1="96" y1="0" x2="96" y2="25" />
  <line x1="120" y1="0" x2="120" y2="25" style="stroke-width:2" />

  <!-- Colored Rectangle -->
  <polygon points="0.000000,0.000000 120.000000,0.000000 120.000000,25.412617 0.000000,25.412617" style="fill:#ECB172A0;stroke-width:0"/>

  <!-- Text -->
  <text x="60.000000" y="45.412617" font-size="1.0rem" font-weight="100" text-anchor="middle" >5000000</text>
  <text x="140.000000" y="12.706308" font-size="1.0rem" font-weight="100" text-anchor="middle" transform="rotate(0,140.000000,12.706308)">1</text>
</svg>
</td>
</tr>
</table></div>
</div>
<p>** Manipulate <code class="docutils literal notranslate"><span class="pre">dask.array</span></code> object as you would a numpy array**</p>
<p>Now that we have an <code class="docutils literal notranslate"><span class="pre">Array</span></code> we perform standard numpy-style computations like arithmetic, mathematics, slicing, reductions, etc..</p>
<p>The interface is familiar, but the actual work is different. dask_array.sum() does not do the same thing as numpy_array.sum().</p>
<p><strong>What’s the difference?</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">dask_array.sum()</span></code> builds an expression of the computation. It does not do the computation yet. <code class="docutils literal notranslate"><span class="pre">numpy_array.sum()</span></code> computes the sum immediately.</p>
<p><em>Why the difference?</em></p>
<p>Dask arrays are split into chunks. Each chunk must have computations run on that chunk explicitly. If the desired answer comes from a small slice of the entire dataset, running the computation over all data would be wasteful of CPU and memory.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">result</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">result</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<table>
<tr>
<td>
<table>
  <thead>
    <tr><td> </td><th> Array </th><th> Chunk </th></tr>
  </thead>
  <tbody>
    <tr><th> Bytes </th><td> 4 B </td> <td> 4 B </td></tr>
    <tr><th> Shape </th><td> () </td> <td> () </td></tr>
    <tr><th> Count </th><td> 14 Tasks </td><td> 1 Chunks </td></tr>
    <tr><th> Type </th><td> float32 </td><td> numpy.ndarray </td></tr>
  </tbody>
</table>
</td>
<td>

</td>
</tr>
</table></div>
</div>
<p><strong>Compute result</strong></p>
<p>Dask.array objects are lazily evaluated. Operations like <code class="docutils literal notranslate"><span class="pre">.sum</span></code> build up a graph of blocked tasks to execute.</p>
<p>We ask for the final result with a call to <code class="docutils literal notranslate"><span class="pre">.compute()</span></code>. This triggers the actual computation.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">result</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
4996559.0
</pre></div></div>
</div>
<div class="section" id="Exercise:-Compute-the-mean">
<h3>Exercise: Compute the mean<a class="headerlink" href="#Exercise:-Compute-the-mean" title="Permalink to this headline">¶</a></h3>
<p>And the variance, std, etc.. This should be a small change to the example above.</p>
<p>Look at what other operations you can do with the Jupyter notebook’s tab-completion.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>
</pre></div>
</div>
</div>
<p>Does this match your result from before?</p>
</div>
</div>
<div class="section" id="Performance-and-Parallelism">
<h2>Performance and Parallelism<a class="headerlink" href="#Performance-and-Parallelism" title="Permalink to this headline">¶</a></h2>
<p><a class="reference internal" href="_images/fail-case.gif"><img alt="b5ff3bbcc7e54ca69c44b0c35e42616a" src="_images/fail-case.gif" style="width: 40%;" /></a></p>
<p>In our first examples we used <code class="docutils literal notranslate"><span class="pre">for</span></code> loops to walk through the array one block at a time. For simple operations like <code class="docutils literal notranslate"><span class="pre">sum</span></code> this is optimal. However for complex operations we may want to traverse through the array differently. In particular we may want the following:</p>
<ol class="arabic simple">
<li><p>Use multiple cores in parallel</p></li>
<li><p>Chain operations on a single blocks before moving on to the next one</p></li>
</ol>
<p>Dask.array translates your array operations into a graph of inter-related tasks with data dependencies between them. Dask then executes this graph in parallel with multiple threads. We’ll discuss more about this in the next section.</p>
<div class="section" id="Example">
<h3>Example<a class="headerlink" href="#Example" title="Permalink to this headline">¶</a></h3>
<ol class="arabic simple">
<li><p>Construct a 20000x20000 array of normally distributed random values broken up into 1000x1000 sized chunks</p></li>
<li><p>Take the mean along one axis</p></li>
<li><p>Take every 100th element</p></li>
</ol>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">dask.array</span> <span class="k">as</span> <span class="nn">da</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">da</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">20000</span><span class="p">,</span> <span class="mi">20000</span><span class="p">),</span>   <span class="c1"># 400 million element array</span>
                              <span class="n">chunks</span><span class="o">=</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">))</span>   <span class="c1"># Cut into 1000x1000 sized chunks</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)[::</span><span class="mi">100</span><span class="p">]</span>                            <span class="c1"># Perform NumPy-style operations</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">x</span><span class="o">.</span><span class="n">nbytes</span> <span class="o">/</span> <span class="mf">1e9</span>  <span class="c1"># Gigabytes of the input processed lazily</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
3.2
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">%%time</span>
<span class="n">y</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>     <span class="c1"># Time to compute the result</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
CPU times: user 22.4 s, sys: 175 ms, total: 22.6 s
Wall time: 11.4 s
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
array([ 9.99969198, 10.00032908,  9.99980064, 10.00041724,  9.99981349,
       10.00104285,  9.99948033,  9.99985473,  9.99990093,  9.99890905,
        9.99932486,  9.99947575, 10.00043148, 10.00007869, 10.00034739,
       10.00049285,  9.99960681, 10.00049702, 10.00303352,  9.99906043,
        9.99960919,  9.99942242, 10.00069304,  9.99892883, 10.00062325,
       10.000094  , 10.00102055, 10.00008965,  9.999591  ,  9.99979009,
       10.00053407,  9.99972973, 10.0002442 , 10.00023763,  9.9987039 ,
        9.99923427, 10.00096115,  9.9990778 ,  9.99912268, 10.0005864 ,
        9.99930832, 10.00003676, 10.00031834, 10.00078135, 10.00090668,
        9.99993908,  9.99919758, 10.00000575, 10.00088931, 10.00024859,
       10.00010038, 10.00012272, 10.00027838, 10.00061913, 10.00039682,
       10.00044831, 10.00046533,  9.9999064 ,  9.99938374,  9.9997668 ,
        9.9995132 , 10.00003598, 10.00039584, 10.00029469, 10.00116402,
       10.0001155 , 10.00028741,  9.9999303 ,  9.99945758,  9.99901394,
        9.99992057, 10.00085797,  9.99995449, 10.00086671, 10.00015464,
        9.99960333, 10.0004132 , 10.0004907 ,  9.99925922,  9.999216  ,
        9.99947386,  9.99938009, 10.00065876, 10.0010177 , 10.00015403,
       10.00009571, 10.00031595, 10.00049176,  9.99977176,  9.99930722,
        9.99960344, 10.00008463, 10.00059067,  9.99992186,  9.99965674,
       10.00012633,  9.9998907 ,  9.99957673, 10.00025414, 10.00064911,
       10.00056386,  9.99848285,  9.99911715,  9.99969649, 10.00010864,
        9.99975483, 10.00076827,  9.99985003, 10.0000484 , 10.00110003,
       10.0008227 , 10.00065395,  9.99877011,  9.99907342, 10.00101296,
        9.99868946,  9.99960578,  9.99946961, 10.00013156,  9.99907913,
        9.99886194,  9.99997981, 10.00070632,  9.99961095,  9.99896875,
        9.9986077 , 10.00006678, 10.00130569,  9.99955794,  9.99995027,
        9.999279  , 10.00142031, 10.0009764 , 10.00111626,  9.99992163,
        9.99924678,  9.99941412, 10.00002782,  9.99913034,  9.99951105,
        9.99980727,  9.9988718 ,  9.99869015, 10.00014199, 10.0009841 ,
        9.9998395 ,  9.99935221,  9.99987837, 10.00013716,  9.999921  ,
        9.99996348,  9.99954774,  9.99944203, 10.00002261, 10.00022018,
       10.00033532, 10.00112131, 10.00021699,  9.99954002, 10.00038047,
        9.9996729 ,  9.99962996, 10.00021386,  9.99915784,  9.9996822 ,
       10.00099897,  9.99853002, 10.0003684 ,  9.99949035, 10.00003819,
       10.00067998, 10.00019009,  9.99896216, 10.00021539,  9.99955584,
        9.99957297,  9.99945817, 10.00021517,  9.99891533,  9.99897651,
        9.99835081,  9.99984497,  9.9999061 , 10.00047391, 10.00108696,
       10.00098914, 10.00035807,  9.99881217, 10.00076924, 10.00085928,
        9.99871725,  9.99974124,  9.99990366,  9.99805282,  9.99921793,
        9.99991788, 10.00107014,  9.99963431, 10.00048034, 10.00047216])
</pre></div></div>
</div>
</div>
</div>
<div class="section" id="Performance-comparision">
<h2>Performance comparision<a class="headerlink" href="#Performance-comparision" title="Permalink to this headline">¶</a></h2>
<p>The following experiment was performed on a heavy personal laptop. Your performance may vary. If you attempt the NumPy version then please ensure that you have more than 4GB of main memory.</p>
<p><strong>NumPy: 19s, Needs gigabytes of memory</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="o">%%</span><span class="n">time</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">20000</span><span class="p">,</span> <span class="mi">20000</span><span class="p">))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)[::</span><span class="mi">100</span><span class="p">]</span>
<span class="n">y</span>

<span class="n">CPU</span> <span class="n">times</span><span class="p">:</span> <span class="n">user</span> <span class="mf">19.6</span> <span class="n">s</span><span class="p">,</span> <span class="n">sys</span><span class="p">:</span> <span class="mi">160</span> <span class="n">ms</span><span class="p">,</span> <span class="n">total</span><span class="p">:</span> <span class="mf">19.8</span> <span class="n">s</span>
<span class="n">Wall</span> <span class="n">time</span><span class="p">:</span> <span class="mf">19.7</span> <span class="n">s</span>
</pre></div>
</div>
<p><strong>Dask Array: 4s, Needs megabytes of memory</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">dask.array</span> <span class="k">as</span> <span class="nn">da</span>

<span class="o">%%</span><span class="n">time</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">da</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">20000</span><span class="p">,</span> <span class="mi">20000</span><span class="p">),</span> <span class="n">chunks</span><span class="o">=</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)[::</span><span class="mi">100</span><span class="p">]</span>
<span class="n">y</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>

<span class="n">CPU</span> <span class="n">times</span><span class="p">:</span> <span class="n">user</span> <span class="mf">29.4</span> <span class="n">s</span><span class="p">,</span> <span class="n">sys</span><span class="p">:</span> <span class="mf">1.07</span> <span class="n">s</span><span class="p">,</span> <span class="n">total</span><span class="p">:</span> <span class="mf">30.5</span> <span class="n">s</span>
<span class="n">Wall</span> <span class="n">time</span><span class="p">:</span> <span class="mf">4.01</span> <span class="n">s</span>
</pre></div>
</div>
<p><strong>Discussion</strong></p>
<p>Notice that the Dask array computation ran in 4 seconds, but used 29.4 seconds of user CPU time. The numpy computation ran in 19.7 seconds and used 19.6 seconds of user CPU time.</p>
<p>Dask finished faster, but used more total CPU time because Dask was able to transparently parallelize the computation because of the chunk size.</p>
<p><em>Questions</em></p>
<ul class="simple">
<li><p>What happens if the dask chunks=(20000,20000)?</p>
<ul>
<li><p>Will the computation run in 4 seconds?</p></li>
<li><p>How much memory will be used?</p></li>
</ul>
</li>
<li><p>What happens if the dask chunks=(25,25)?</p>
<ul>
<li><p>What happens to CPU and memory?</p></li>
</ul>
</li>
</ul>
<div class="section" id="Exercise:-Meteorological-data">
<h3>Exercise: Meteorological data<a class="headerlink" href="#Exercise:-Meteorological-data" title="Permalink to this headline">¶</a></h3>
<p>There is 2GB of somewhat artifical weather data in HDF5 files in <code class="docutils literal notranslate"><span class="pre">data/weather-big/*.hdf5</span></code>. We’ll use the <code class="docutils literal notranslate"><span class="pre">h5py</span></code> library to interact with this data and <code class="docutils literal notranslate"><span class="pre">dask.array</span></code> to compute on it.</p>
<p>Our goal is to visualize the average temperature on the surface of the Earth for this month. This will require a mean over all of this data. We’ll do this in the following steps</p>
<ol class="arabic simple">
<li><p>Create <code class="docutils literal notranslate"><span class="pre">h5py.Dataset</span></code> objects for each of the days of data on disk (<code class="docutils literal notranslate"><span class="pre">dsets</span></code>)</p></li>
<li><p>Wrap these with <code class="docutils literal notranslate"><span class="pre">da.from_array</span></code> calls</p></li>
<li><p>Stack these datasets along time with a call to <code class="docutils literal notranslate"><span class="pre">da.stack</span></code></p></li>
<li><p>Compute the mean along the newly stacked time axis with the <code class="docutils literal notranslate"><span class="pre">.mean()</span></code> method</p></li>
<li><p>Visualize the result with <code class="docutils literal notranslate"><span class="pre">matplotlib.pyplot.imshow</span></code></p></li>
</ol>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">%</span><span class="k">run</span> prep.py -d weather
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">h5py</span>
<span class="kn">from</span> <span class="nn">glob</span> <span class="kn">import</span> <span class="n">glob</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="n">filenames</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">glob</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="s1">&#39;weather-big&#39;</span><span class="p">,</span> <span class="s1">&#39;*.hdf5&#39;</span><span class="p">)))</span>
<span class="n">dsets</span> <span class="o">=</span> <span class="p">[</span><span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)[</span><span class="s1">&#39;/t2m&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">filename</span> <span class="ow">in</span> <span class="n">filenames</span><span class="p">]</span>
<span class="n">dsets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;HDF5 dataset &#34;t2m&#34;: shape (180, 360), type &#34;&lt;f8&#34;&gt;
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">dsets</span><span class="p">[</span><span class="mi">0</span><span class="p">][:</span><span class="mi">5</span><span class="p">,</span> <span class="p">:</span><span class="mi">5</span><span class="p">]</span>  <span class="c1"># Slicing into h5py.Dataset object gives a numpy array</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
array([[84.75, 84.75, 84.75, 84.75, 84.75],
       [83.  , 83.  , 83.  , 83.  , 83.  ],
       [84.5 , 84.  , 84.  , 84.  , 84.  ],
       [81.25, 81.25, 81.25, 81.25, 81.25],
       [77.75, 77.75, 77.75, 77.75, 77.75]])
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">dsets</span><span class="p">[</span><span class="mi">0</span><span class="p">][::</span><span class="mi">4</span><span class="p">,</span> <span class="p">::</span><span class="mi">4</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;RdBu_r&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/03_array_56_0.png" src="_images/03_array_56_0.png" />
</div>
</div>
<p><strong>Integrate with ``dask.array``</strong></p>
<p>Make a list of <code class="docutils literal notranslate"><span class="pre">dask.array</span></code> objects out of your list of <code class="docutils literal notranslate"><span class="pre">h5py.Dataset</span></code> objects using the <code class="docutils literal notranslate"><span class="pre">da.from_array</span></code> function with a chunk size of <code class="docutils literal notranslate"><span class="pre">(500,</span> <span class="pre">500)</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">arrays</span> <span class="o">=</span> <span class="p">[</span><span class="n">da</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">dset</span><span class="p">,</span> <span class="n">chunks</span><span class="o">=</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="mi">500</span><span class="p">))</span> <span class="k">for</span> <span class="n">dset</span> <span class="ow">in</span> <span class="n">dsets</span><span class="p">]</span>
<span class="n">arrays</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[dask.array&lt;array, shape=(180, 360), dtype=float64, chunksize=(180, 360), chunktype=numpy.ndarray&gt;,
 dask.array&lt;array, shape=(180, 360), dtype=float64, chunksize=(180, 360), chunktype=numpy.ndarray&gt;,
 dask.array&lt;array, shape=(180, 360), dtype=float64, chunksize=(180, 360), chunktype=numpy.ndarray&gt;,
 dask.array&lt;array, shape=(180, 360), dtype=float64, chunksize=(180, 360), chunktype=numpy.ndarray&gt;,
 dask.array&lt;array, shape=(180, 360), dtype=float64, chunksize=(180, 360), chunktype=numpy.ndarray&gt;,
 dask.array&lt;array, shape=(180, 360), dtype=float64, chunksize=(180, 360), chunktype=numpy.ndarray&gt;,
 dask.array&lt;array, shape=(180, 360), dtype=float64, chunksize=(180, 360), chunktype=numpy.ndarray&gt;,
 dask.array&lt;array, shape=(180, 360), dtype=float64, chunksize=(180, 360), chunktype=numpy.ndarray&gt;,
 dask.array&lt;array, shape=(180, 360), dtype=float64, chunksize=(180, 360), chunktype=numpy.ndarray&gt;,
 dask.array&lt;array, shape=(180, 360), dtype=float64, chunksize=(180, 360), chunktype=numpy.ndarray&gt;,
 dask.array&lt;array, shape=(180, 360), dtype=float64, chunksize=(180, 360), chunktype=numpy.ndarray&gt;,
 dask.array&lt;array, shape=(180, 360), dtype=float64, chunksize=(180, 360), chunktype=numpy.ndarray&gt;,
 dask.array&lt;array, shape=(180, 360), dtype=float64, chunksize=(180, 360), chunktype=numpy.ndarray&gt;,
 dask.array&lt;array, shape=(180, 360), dtype=float64, chunksize=(180, 360), chunktype=numpy.ndarray&gt;,
 dask.array&lt;array, shape=(180, 360), dtype=float64, chunksize=(180, 360), chunktype=numpy.ndarray&gt;,
 dask.array&lt;array, shape=(180, 360), dtype=float64, chunksize=(180, 360), chunktype=numpy.ndarray&gt;,
 dask.array&lt;array, shape=(180, 360), dtype=float64, chunksize=(180, 360), chunktype=numpy.ndarray&gt;,
 dask.array&lt;array, shape=(180, 360), dtype=float64, chunksize=(180, 360), chunktype=numpy.ndarray&gt;,
 dask.array&lt;array, shape=(180, 360), dtype=float64, chunksize=(180, 360), chunktype=numpy.ndarray&gt;,
 dask.array&lt;array, shape=(180, 360), dtype=float64, chunksize=(180, 360), chunktype=numpy.ndarray&gt;,
 dask.array&lt;array, shape=(180, 360), dtype=float64, chunksize=(180, 360), chunktype=numpy.ndarray&gt;,
 dask.array&lt;array, shape=(180, 360), dtype=float64, chunksize=(180, 360), chunktype=numpy.ndarray&gt;,
 dask.array&lt;array, shape=(180, 360), dtype=float64, chunksize=(180, 360), chunktype=numpy.ndarray&gt;,
 dask.array&lt;array, shape=(180, 360), dtype=float64, chunksize=(180, 360), chunktype=numpy.ndarray&gt;,
 dask.array&lt;array, shape=(180, 360), dtype=float64, chunksize=(180, 360), chunktype=numpy.ndarray&gt;,
 dask.array&lt;array, shape=(180, 360), dtype=float64, chunksize=(180, 360), chunktype=numpy.ndarray&gt;,
 dask.array&lt;array, shape=(180, 360), dtype=float64, chunksize=(180, 360), chunktype=numpy.ndarray&gt;,
 dask.array&lt;array, shape=(180, 360), dtype=float64, chunksize=(180, 360), chunktype=numpy.ndarray&gt;,
 dask.array&lt;array, shape=(180, 360), dtype=float64, chunksize=(180, 360), chunktype=numpy.ndarray&gt;,
 dask.array&lt;array, shape=(180, 360), dtype=float64, chunksize=(180, 360), chunktype=numpy.ndarray&gt;,
 dask.array&lt;array, shape=(180, 360), dtype=float64, chunksize=(180, 360), chunktype=numpy.ndarray&gt;]
</pre></div></div>
</div>
<p><strong>Stack this list of ``dask.array`` objects into a single ``dask.array`` object with ``da.stack``</strong></p>
<p>Stack these along the first axis so that the shape of the resulting array is <code class="docutils literal notranslate"><span class="pre">(31,</span> <span class="pre">5760,</span> <span class="pre">11520)</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">x</span> <span class="o">=</span> <span class="n">da</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">arrays</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">x</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<table>
<tr>
<td>
<table>
  <thead>
    <tr><td> </td><th> Array </th><th> Chunk </th></tr>
  </thead>
  <tbody>
    <tr><th> Bytes </th><td> 16.07 MB </td> <td> 518.40 kB </td></tr>
    <tr><th> Shape </th><td> (31, 180, 360) </td> <td> (1, 180, 360) </td></tr>
    <tr><th> Count </th><td> 93 Tasks </td><td> 31 Chunks </td></tr>
    <tr><th> Type </th><td> float64 </td><td> numpy.ndarray </td></tr>
  </tbody>
</table>
</td>
<td>
<svg width="202" height="132" style="stroke:rgb(0,0,0);stroke-width:1" >

  <!-- Horizontal lines -->
  <line x1="10" y1="0" x2="32" y2="22" style="stroke-width:2" />
  <line x1="10" y1="60" x2="32" y2="82" style="stroke-width:2" />

  <!-- Vertical lines -->
  <line x1="10" y1="0" x2="10" y2="60" style="stroke-width:2" />
  <line x1="10" y1="0" x2="10" y2="60" />
  <line x1="11" y1="1" x2="11" y2="61" />
  <line x1="12" y1="2" x2="12" y2="62" />
  <line x1="12" y1="2" x2="12" y2="62" />
  <line x1="13" y1="3" x2="13" y2="63" />
  <line x1="14" y1="4" x2="14" y2="64" />
  <line x1="15" y1="5" x2="15" y2="65" />
  <line x1="15" y1="5" x2="15" y2="65" />
  <line x1="16" y1="6" x2="16" y2="66" />
  <line x1="17" y1="7" x2="17" y2="67" />
  <line x1="17" y1="7" x2="17" y2="67" />
  <line x1="18" y1="8" x2="18" y2="68" />
  <line x1="19" y1="9" x2="19" y2="69" />
  <line x1="20" y1="10" x2="20" y2="70" />
  <line x1="20" y1="10" x2="20" y2="70" />
  <line x1="21" y1="11" x2="21" y2="71" />
  <line x1="22" y1="12" x2="22" y2="72" />
  <line x1="22" y1="12" x2="22" y2="72" />
  <line x1="23" y1="13" x2="23" y2="73" />
  <line x1="24" y1="14" x2="24" y2="74" />
  <line x1="25" y1="15" x2="25" y2="75" />
  <line x1="25" y1="15" x2="25" y2="75" />
  <line x1="26" y1="16" x2="26" y2="76" />
  <line x1="27" y1="17" x2="27" y2="77" />
  <line x1="27" y1="17" x2="27" y2="77" />
  <line x1="28" y1="18" x2="28" y2="78" />
  <line x1="29" y1="19" x2="29" y2="79" />
  <line x1="30" y1="20" x2="30" y2="80" />
  <line x1="30" y1="20" x2="30" y2="80" />
  <line x1="31" y1="21" x2="31" y2="81" />
  <line x1="32" y1="22" x2="32" y2="82" style="stroke-width:2" />

  <!-- Colored Rectangle -->
  <polygon points="10.000000,0.000000 32.207396,22.207396 32.207396,82.207396 10.000000,60.000000" style="fill:#ECB172A0;stroke-width:0"/>

  <!-- Horizontal lines -->
  <line x1="10" y1="0" x2="130" y2="0" style="stroke-width:2" />
  <line x1="10" y1="0" x2="130" y2="0" />
  <line x1="11" y1="1" x2="131" y2="1" />
  <line x1="12" y1="2" x2="132" y2="2" />
  <line x1="12" y1="2" x2="132" y2="2" />
  <line x1="13" y1="3" x2="133" y2="3" />
  <line x1="14" y1="4" x2="134" y2="4" />
  <line x1="15" y1="5" x2="135" y2="5" />
  <line x1="15" y1="5" x2="135" y2="5" />
  <line x1="16" y1="6" x2="136" y2="6" />
  <line x1="17" y1="7" x2="137" y2="7" />
  <line x1="17" y1="7" x2="137" y2="7" />
  <line x1="18" y1="8" x2="138" y2="8" />
  <line x1="19" y1="9" x2="139" y2="9" />
  <line x1="20" y1="10" x2="140" y2="10" />
  <line x1="20" y1="10" x2="140" y2="10" />
  <line x1="21" y1="11" x2="141" y2="11" />
  <line x1="22" y1="12" x2="142" y2="12" />
  <line x1="22" y1="12" x2="142" y2="12" />
  <line x1="23" y1="13" x2="143" y2="13" />
  <line x1="24" y1="14" x2="144" y2="14" />
  <line x1="25" y1="15" x2="145" y2="15" />
  <line x1="25" y1="15" x2="145" y2="15" />
  <line x1="26" y1="16" x2="146" y2="16" />
  <line x1="27" y1="17" x2="147" y2="17" />
  <line x1="27" y1="17" x2="147" y2="17" />
  <line x1="28" y1="18" x2="148" y2="18" />
  <line x1="29" y1="19" x2="149" y2="19" />
  <line x1="30" y1="20" x2="150" y2="20" />
  <line x1="30" y1="20" x2="150" y2="20" />
  <line x1="31" y1="21" x2="151" y2="21" />
  <line x1="32" y1="22" x2="152" y2="22" style="stroke-width:2" />

  <!-- Vertical lines -->
  <line x1="10" y1="0" x2="32" y2="22" style="stroke-width:2" />
  <line x1="130" y1="0" x2="152" y2="22" style="stroke-width:2" />

  <!-- Colored Rectangle -->
  <polygon points="10.000000,0.000000 130.000000,0.000000 152.207396,22.207396 32.207396,22.207396" style="fill:#ECB172A0;stroke-width:0"/>

  <!-- Horizontal lines -->
  <line x1="32" y1="22" x2="152" y2="22" style="stroke-width:2" />
  <line x1="32" y1="82" x2="152" y2="82" style="stroke-width:2" />

  <!-- Vertical lines -->
  <line x1="32" y1="22" x2="32" y2="82" style="stroke-width:2" />
  <line x1="152" y1="22" x2="152" y2="82" style="stroke-width:2" />

  <!-- Colored Rectangle -->
  <polygon points="32.207396,22.207396 152.207396,22.207396 152.207396,82.207396 32.207396,82.207396" style="fill:#ECB172A0;stroke-width:0"/>

  <!-- Text -->
  <text x="92.207396" y="102.207396" font-size="1.0rem" font-weight="100" text-anchor="middle" >360</text>
  <text x="172.207396" y="52.207396" font-size="1.0rem" font-weight="100" text-anchor="middle" transform="rotate(-90,172.207396,52.207396)">180</text>
  <text x="11.103698" y="91.103698" font-size="1.0rem" font-weight="100" text-anchor="middle" transform="rotate(45,11.103698,91.103698)">31</text>
</svg>
</td>
</tr>
</table></div>
</div>
<p><strong>Plot the mean of this array along the time (``0th``) axis</strong></p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># complete the following:</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;RdBu_r&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">TypeError</span>                                 Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-19-d2371b8f5286&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-intense-fg ansi-bold">      1</span> <span class="ansi-red-fg"># complete the following:</span>
<span class="ansi-green-intense-fg ansi-bold">      2</span> fig <span class="ansi-blue-fg">=</span> plt<span class="ansi-blue-fg">.</span>figure<span class="ansi-blue-fg">(</span>figsize<span class="ansi-blue-fg">=</span><span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">16</span><span class="ansi-blue-fg">,</span> <span class="ansi-cyan-fg">8</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">----&gt; 3</span><span class="ansi-red-fg"> </span>plt<span class="ansi-blue-fg">.</span>imshow<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">...</span><span class="ansi-blue-fg">,</span> cmap<span class="ansi-blue-fg">=</span><span class="ansi-blue-fg">&#39;RdBu_r&#39;</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/miniconda/envs/test/lib/python3.7/site-packages/matplotlib/pyplot.py</span> in <span class="ansi-cyan-fg">imshow</span><span class="ansi-blue-fg">(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">   2649</span>         filternorm<span class="ansi-blue-fg">=</span>filternorm<span class="ansi-blue-fg">,</span> filterrad<span class="ansi-blue-fg">=</span>filterrad<span class="ansi-blue-fg">,</span> imlim<span class="ansi-blue-fg">=</span>imlim<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   2650</span>         resample=resample, url=url, **({&#34;data&#34;: data} if data is not
<span class="ansi-green-fg">-&gt; 2651</span><span class="ansi-red-fg">         None else {}), **kwargs)
</span><span class="ansi-green-intense-fg ansi-bold">   2652</span>     sci<span class="ansi-blue-fg">(</span>__ret<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   2653</span>     <span class="ansi-green-fg">return</span> __ret

<span class="ansi-green-fg">~/miniconda/envs/test/lib/python3.7/site-packages/matplotlib/__init__.py</span> in <span class="ansi-cyan-fg">inner</span><span class="ansi-blue-fg">(ax, data, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">   1563</span>     <span class="ansi-green-fg">def</span> inner<span class="ansi-blue-fg">(</span>ax<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> data<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">None</span><span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">   1564</span>         <span class="ansi-green-fg">if</span> data <span class="ansi-green-fg">is</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">-&gt; 1565</span><span class="ansi-red-fg">             </span><span class="ansi-green-fg">return</span> func<span class="ansi-blue-fg">(</span>ax<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">*</span>map<span class="ansi-blue-fg">(</span>sanitize_sequence<span class="ansi-blue-fg">,</span> args<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1566</span>
<span class="ansi-green-intense-fg ansi-bold">   1567</span>         bound <span class="ansi-blue-fg">=</span> new_sig<span class="ansi-blue-fg">.</span>bind<span class="ansi-blue-fg">(</span>ax<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/miniconda/envs/test/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py</span> in <span class="ansi-cyan-fg">wrapper</span><span class="ansi-blue-fg">(*args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    356</span>                 <span class="ansi-blue-fg">f&#34;%(removal)s.  If any parameter follows {name!r}, they &#34;</span>
<span class="ansi-green-intense-fg ansi-bold">    357</span>                 f&#34;should be pass as keyword, not positionally.&#34;)
<span class="ansi-green-fg">--&gt; 358</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> func<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    359</span>
<span class="ansi-green-intense-fg ansi-bold">    360</span>     <span class="ansi-green-fg">return</span> wrapper

<span class="ansi-green-fg">~/miniconda/envs/test/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py</span> in <span class="ansi-cyan-fg">wrapper</span><span class="ansi-blue-fg">(*args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    356</span>                 <span class="ansi-blue-fg">f&#34;%(removal)s.  If any parameter follows {name!r}, they &#34;</span>
<span class="ansi-green-intense-fg ansi-bold">    357</span>                 f&#34;should be pass as keyword, not positionally.&#34;)
<span class="ansi-green-fg">--&gt; 358</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> func<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    359</span>
<span class="ansi-green-intense-fg ansi-bold">    360</span>     <span class="ansi-green-fg">return</span> wrapper

<span class="ansi-green-fg">~/miniconda/envs/test/lib/python3.7/site-packages/matplotlib/axes/_axes.py</span> in <span class="ansi-cyan-fg">imshow</span><span class="ansi-blue-fg">(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">   5613</span>                               resample=resample, **kwargs)
<span class="ansi-green-intense-fg ansi-bold">   5614</span>
<span class="ansi-green-fg">-&gt; 5615</span><span class="ansi-red-fg">         </span>im<span class="ansi-blue-fg">.</span>set_data<span class="ansi-blue-fg">(</span>X<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   5616</span>         im<span class="ansi-blue-fg">.</span>set_alpha<span class="ansi-blue-fg">(</span>alpha<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   5617</span>         <span class="ansi-green-fg">if</span> im<span class="ansi-blue-fg">.</span>get_clip_path<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span> <span class="ansi-green-fg">is</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">~/miniconda/envs/test/lib/python3.7/site-packages/matplotlib/image.py</span> in <span class="ansi-cyan-fg">set_data</span><span class="ansi-blue-fg">(self, A)</span>
<span class="ansi-green-intense-fg ansi-bold">    692</span>                 not np.can_cast(self._A.dtype, float, &#34;same_kind&#34;)):
<span class="ansi-green-intense-fg ansi-bold">    693</span>             raise TypeError(&#34;Image data of dtype {} cannot be converted to &#34;
<span class="ansi-green-fg">--&gt; 694</span><span class="ansi-red-fg">                             &#34;float&#34;.format(self._A.dtype))
</span><span class="ansi-green-intense-fg ansi-bold">    695</span>
<span class="ansi-green-intense-fg ansi-bold">    696</span>         if not (self._A.ndim == 2

<span class="ansi-red-fg">TypeError</span>: Image data of dtype object cannot be converted to float
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/03_array_66_1.png" src="_images/03_array_66_1.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">result</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;RdBu_r&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/03_array_67_0.png" src="_images/03_array_67_0.png" />
</div>
</div>
<p><strong>Plot the difference of the first day from the mean</strong></p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">result</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;RdBu_r&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/03_array_70_0.png" src="_images/03_array_70_0.png" />
</div>
</div>
</div>
<div class="section" id="Exercise:-Subsample-and-store">
<h3>Exercise: Subsample and store<a class="headerlink" href="#Exercise:-Subsample-and-store" title="Permalink to this headline">¶</a></h3>
<p>In the above exercise the result of our computation is small, so we can call <code class="docutils literal notranslate"><span class="pre">compute</span></code> safely. Sometimes our result is still too large to fit into memory and we want to save it to disk. In these cases you can use one of the following two functions</p>
<ol class="arabic">
<li><p><code class="docutils literal notranslate"><span class="pre">da.store</span></code>: Store dask.array into any object that supports numpy setitem syntax, e.g.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">f</span> <span class="o">=</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="s1">&#39;myfile.hdf5&#39;</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">create_dataset</span><span class="p">(</span><span class="n">shape</span><span class="o">=...</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=...</span><span class="p">)</span>

<span class="n">da</span><span class="o">.</span><span class="n">store</span><span class="p">(</span><span class="n">my_dask_array</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">da.to_hdf5</span></code>: A specialized function that creates and stores a <code class="docutils literal notranslate"><span class="pre">dask.array</span></code> object into an <code class="docutils literal notranslate"><span class="pre">HDF5</span></code> file.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">da</span><span class="o">.</span><span class="n">to_hdf5</span><span class="p">(</span><span class="s1">&#39;data/myfile.hdf5&#39;</span><span class="p">,</span> <span class="s1">&#39;/output&#39;</span><span class="p">,</span> <span class="n">my_dask_array</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ol>
<p>The task in this exercise is to <strong>use numpy step slicing to subsample the full dataset by a factor of two in both the latitude and longitude direction and then store this result to disk</strong> using one of the functions listed above.</p>
<p>As a reminder, Python slicing takes three elements</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">start</span><span class="p">:</span><span class="n">stop</span><span class="p">:</span><span class="n">step</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">L</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">L</span><span class="p">[::</span><span class="mi">3</span><span class="p">]</span>
<span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">7</span><span class="p">]</span>
</pre></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># ...</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">h5py</span>
<span class="kn">from</span> <span class="nn">glob</span> <span class="kn">import</span> <span class="n">glob</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">dask.array</span> <span class="k">as</span> <span class="nn">da</span>

<span class="n">filenames</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">glob</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="s1">&#39;weather-big&#39;</span><span class="p">,</span> <span class="s1">&#39;*.hdf5&#39;</span><span class="p">)))</span>
<span class="n">dsets</span> <span class="o">=</span> <span class="p">[</span><span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)[</span><span class="s1">&#39;/t2m&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">filename</span> <span class="ow">in</span> <span class="n">filenames</span><span class="p">]</span>

<span class="n">arrays</span> <span class="o">=</span> <span class="p">[</span><span class="n">da</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">dset</span><span class="p">,</span> <span class="n">chunks</span><span class="o">=</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="mi">500</span><span class="p">))</span> <span class="k">for</span> <span class="n">dset</span> <span class="ow">in</span> <span class="n">dsets</span><span class="p">]</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">da</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">arrays</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span> <span class="p">::</span><span class="mi">2</span><span class="p">,</span> <span class="p">::</span><span class="mi">2</span><span class="p">]</span>

<span class="n">da</span><span class="o">.</span><span class="n">to_zarr</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="s1">&#39;myfile.zarr&#39;</span><span class="p">),</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Example:-Lennard-Jones-potential">
<h2>Example: Lennard-Jones potential<a class="headerlink" href="#Example:-Lennard-Jones-potential" title="Permalink to this headline">¶</a></h2>
<p>The <a class="reference external" href="https://en.wikipedia.org/wiki/Lennard-Jones_potential">Lennard-Jones</a> is used in partical simuluations in physics, chemistry and engineering. It is highly parallelizable.</p>
<p>First, we’ll run and profile the Numpy version on 7,000 particles.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># make a random collection of particles</span>
<span class="k">def</span> <span class="nf">make_cluster</span><span class="p">(</span><span class="n">natoms</span><span class="p">,</span> <span class="n">radius</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">1981</span><span class="p">):</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">cluster</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">radius</span><span class="p">,</span> <span class="p">(</span><span class="n">natoms</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span><span class="o">-</span><span class="mf">0.5</span>
    <span class="k">return</span> <span class="n">cluster</span>

<span class="k">def</span> <span class="nf">lj</span><span class="p">(</span><span class="n">r2</span><span class="p">):</span>
    <span class="n">sr6</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.</span><span class="o">/</span><span class="n">r2</span><span class="p">)</span><span class="o">**</span><span class="mi">3</span>
    <span class="n">pot</span> <span class="o">=</span> <span class="mf">4.</span><span class="o">*</span><span class="p">(</span><span class="n">sr6</span><span class="o">*</span><span class="n">sr6</span> <span class="o">-</span> <span class="n">sr6</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">pot</span>

<span class="c1"># build the matrix of distances</span>
<span class="k">def</span> <span class="nf">distances</span><span class="p">(</span><span class="n">cluster</span><span class="p">):</span>
    <span class="n">diff</span> <span class="o">=</span> <span class="n">cluster</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:]</span> <span class="o">-</span> <span class="n">cluster</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>
    <span class="n">mat</span> <span class="o">=</span> <span class="p">(</span><span class="n">diff</span><span class="o">*</span><span class="n">diff</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mat</span>

<span class="c1"># the lj function is evaluated over the upper traingle</span>
<span class="c1"># after removing distances near zero</span>
<span class="k">def</span> <span class="nf">potential</span><span class="p">(</span><span class="n">cluster</span><span class="p">):</span>
    <span class="n">d2</span> <span class="o">=</span> <span class="n">distances</span><span class="p">(</span><span class="n">cluster</span><span class="p">)</span>
    <span class="n">dtri</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">d2</span><span class="p">)</span>
    <span class="n">energy</span> <span class="o">=</span> <span class="n">lj</span><span class="p">(</span><span class="n">dtri</span><span class="p">[</span><span class="n">dtri</span> <span class="o">&gt;</span> <span class="mf">1e-6</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">energy</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">cluster</span> <span class="o">=</span> <span class="n">make_cluster</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="mf">7e3</span><span class="p">),</span> <span class="n">radius</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">%</span><span class="k">time</span> potential(cluster)
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
distributed.worker - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 1.68 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.68 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Worker is at 91% memory usage. Pausing worker.  Process memory: 1.92 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.92 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Worker is at 102% memory usage. Pausing worker.  Process memory: 2.13 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 2.13 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Worker is at 112% memory usage. Pausing worker.  Process memory: 2.35 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 2.35 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 2.58 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 2.58 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 2.58 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 2.59 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 2.67 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 2.67 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 2.67 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 2.68 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 3.00 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 3.00 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 3.00 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 3.00 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 3.04 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 3.04 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 3.04 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 3.04 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 3.04 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 3.04 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 3.04 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 3.04 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 3.04 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 3.04 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 3.04 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 3.04 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 3.04 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 3.04 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 3.04 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 3.04 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Worker is at 49% memory usage. Resuming worker. Process memory: 1.04 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Worker is at 49% memory usage. Resuming worker. Process memory: 1.04 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Worker is at 49% memory usage. Resuming worker. Process memory: 1.04 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Worker is at 50% memory usage. Resuming worker. Process memory: 1.05 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.50 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.50 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.50 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.50 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.52 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.52 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.52 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.52 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.55 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.55 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.55 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.55 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.57 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.57 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.57 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.57 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.60 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.60 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.60 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.60 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.62 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.62 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.62 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.62 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.65 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.65 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.65 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.65 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.67 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.67 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.67 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.67 GB -- Worker memory limit: 2.09 GB
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
CPU times: user 4.1 s, sys: 1.38 s, total: 5.48 s
Wall time: 4.72 s
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
-0.21282893668845293
</pre></div></div>
</div>
<p>Notice that the most time consuming function is <code class="docutils literal notranslate"><span class="pre">distances</span></code>:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># this would open in another browser tab</span>
<span class="c1"># %load_ext snakeviz</span>
<span class="c1"># %snakeviz potential(cluster)</span>

<span class="c1"># alternative simple version given text results in this tab</span>
<span class="o">%</span><span class="k">prun</span> -s tottime potential(cluster)
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
distributed.worker - WARNING - Worker is at 87% memory usage. Pausing worker.  Process memory: 1.83 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.83 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Worker is at 88% memory usage. Pausing worker.  Process memory: 1.84 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.84 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Worker is at 88% memory usage. Pausing worker.  Process memory: 1.85 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.85 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Worker is at 88% memory usage. Pausing worker.  Process memory: 1.86 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.86 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 2.49 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 2.50 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 2.50 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 2.51 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 3.04 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 3.04 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 3.04 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 3.04 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 3.04 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 3.04 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 3.04 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 3.04 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 3.04 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 3.04 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 3.04 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 3.04 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 3.04 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 3.04 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 3.04 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 3.04 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Worker is at 35% memory usage. Resuming worker. Process memory: 735.57 MB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Worker is at 35% memory usage. Resuming worker. Process memory: 737.67 MB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Worker is at 35% memory usage. Resuming worker. Process memory: 739.77 MB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Worker is at 35% memory usage. Resuming worker. Process memory: 740.25 MB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.48 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.48 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.48 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.48 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.51 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.51 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.51 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.51 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.53 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.53 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.53 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.53 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.56 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.56 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.56 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.56 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.58 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.58 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.58 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.58 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.61 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.61 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.61 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.61 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.63 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.63 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.63 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.63 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.66 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.66 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.66 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.66 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.67 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.67 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.67 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.67 GB -- Worker memory limit: 2.09 GB
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

</pre></div></div>
</div>
<div class="section" id="Dask-version">
<h3>Dask version<a class="headerlink" href="#Dask-version" title="Permalink to this headline">¶</a></h3>
<p>Here’s the Dask version. Only the <code class="docutils literal notranslate"><span class="pre">potential</span></code> function needs to be rewritten to best utilize Dask.</p>
<p>Note that <code class="docutils literal notranslate"><span class="pre">da.nansum</span></code> has been used over the full <span class="math notranslate nohighlight">\(NxN\)</span> distance matrix to improve parallel efficiency.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">dask.array</span> <span class="k">as</span> <span class="nn">da</span>

<span class="c1"># compute the potential on the entire</span>
<span class="c1"># matrix of distances and ignore division by zero</span>
<span class="k">def</span> <span class="nf">potential_dask</span><span class="p">(</span><span class="n">cluster</span><span class="p">):</span>
    <span class="n">d2</span> <span class="o">=</span> <span class="n">distances</span><span class="p">(</span><span class="n">cluster</span><span class="p">)</span>
    <span class="n">energy</span> <span class="o">=</span> <span class="n">da</span><span class="o">.</span><span class="n">nansum</span><span class="p">(</span><span class="n">lj</span><span class="p">(</span><span class="n">d2</span><span class="p">))</span><span class="o">/</span><span class="mf">2.</span>
    <span class="k">return</span> <span class="n">energy</span>
</pre></div>
</div>
</div>
<p>Let’s convert the NumPy array to a Dask array. Since the entire NumPy array fits in memory it is more computationally efficient to chunk the array by number of CPU cores.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[29]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">os</span> <span class="kn">import</span> <span class="n">cpu_count</span>

<span class="n">dcluster</span> <span class="o">=</span> <span class="n">da</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">cluster</span><span class="p">,</span> <span class="n">chunks</span><span class="o">=</span><span class="n">cluster</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">//</span><span class="n">cpu_count</span><span class="p">())</span>
</pre></div>
</div>
</div>
<p>This step should scale quite well with number of cores. The warnings are complaining about dividing by zero, which is why we used <code class="docutils literal notranslate"><span class="pre">da.nansum</span></code> in <code class="docutils literal notranslate"><span class="pre">potential_dask</span></code>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[30]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">e</span> <span class="o">=</span> <span class="n">potential_dask</span><span class="p">(</span><span class="n">dcluster</span><span class="p">)</span>
<span class="o">%</span><span class="k">time</span> e.compute()
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
distributed.worker - WARNING - Worker is at 84% memory usage. Pausing worker.  Process memory: 1.77 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.78 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Worker is at 85% memory usage. Pausing worker.  Process memory: 1.79 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.79 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Worker is at 85% memory usage. Pausing worker.  Process memory: 1.79 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.79 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Worker is at 85% memory usage. Pausing worker.  Process memory: 1.80 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.80 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 2.32 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 2.32 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 2.32 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 2.32 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 2.85 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 2.85 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 2.85 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 2.85 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 2.55 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 2.55 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 2.55 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 2.55 GB -- Worker memory limit: 2.09 GB
/home/travis/miniconda/envs/test/lib/python3.7/site-packages/dask/core.py:119: RuntimeWarning: divide by zero encountered in true_divide
  return func(*args2)
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 2.56 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 2.56 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 2.56 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 2.56 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Worker is at 72% memory usage. Resuming worker. Process memory: 1.51 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.51 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Worker is at 72% memory usage. Resuming worker. Process memory: 1.51 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.51 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Worker is at 72% memory usage. Resuming worker. Process memory: 1.51 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.51 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Worker is at 72% memory usage. Resuming worker. Process memory: 1.51 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.51 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.65 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.65 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.65 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.65 GB -- Worker memory limit: 2.09 GB
/home/travis/miniconda/envs/test/lib/python3.7/site-packages/dask/core.py:119: RuntimeWarning: invalid value encountered in subtract
  return func(*args2)
distributed.worker - WARNING - Worker is at 93% memory usage. Pausing worker.  Process memory: 1.96 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.96 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Worker is at 94% memory usage. Pausing worker.  Process memory: 1.97 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.97 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Worker is at 94% memory usage. Pausing worker.  Process memory: 1.97 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.97 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Worker is at 94% memory usage. Pausing worker.  Process memory: 1.98 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.98 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.80 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.80 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.81 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.81 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Worker is at 75% memory usage. Resuming worker. Process memory: 1.59 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.59 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Worker is at 75% memory usage. Resuming worker. Process memory: 1.59 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.59 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Worker is at 76% memory usage. Resuming worker. Process memory: 1.59 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.59 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Worker is at 76% memory usage. Resuming worker. Process memory: 1.60 GB -- Worker memory limit: 2.09 GB
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 1.60 GB -- Worker memory limit: 2.09 GB
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
CPU times: user 7.59 s, sys: 1.42 s, total: 9 s
Wall time: 4.58 s
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[30]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
-0.21282893668845299
</pre></div></div>
</div>
</div>
</div>
<div class="section" id="Limitations">
<h2>Limitations<a class="headerlink" href="#Limitations" title="Permalink to this headline">¶</a></h2>
<p>Dask Array does not implement the entire numpy interface. Users expecting this will be disappointed. Notably Dask Array has the following failings:</p>
<ol class="arabic simple">
<li><p>Dask does not implement all of <code class="docutils literal notranslate"><span class="pre">np.linalg</span></code>. This has been done by a number of excellent BLAS/LAPACK implementations and is the focus of numerous ongoing academic research projects.</p></li>
<li><p>Dask Array does not support some operations where the resulting shape depends on the values of the array. For those that it does support (for example, masking one Dask Array with another boolean mask), the chunk sizes will be unknown, which may cause issues with other operations that need to know the chunk sizes.</p></li>
<li><p>Dask Array does not attempt operations like <code class="docutils literal notranslate"><span class="pre">sort</span></code> which are notoriously difficult to do in parallel and are of somewhat diminished value on very large data (you rarely actually need a full sort). Often we include parallel-friendly alternatives like <code class="docutils literal notranslate"><span class="pre">topk</span></code>.</p></li>
<li><p>Dask development is driven by immediate need, and so many lesser used functions, like <code class="docutils literal notranslate"><span class="pre">np.sometrue</span></code> have not been implemented purely out of laziness. These would make excellent community contributions.</p></li>
</ol>
<ul class="simple">
<li><p><a class="reference external" href="https://docs.dask.org/en/latest/array.html">Array documentation</a></p></li>
<li><p><a class="reference external" href="https://youtu.be/9h_61hXCDuI">Array screencast</a></p></li>
<li><p><a class="reference external" href="https://docs.dask.org/en/latest/array-api.html">Array API</a></p></li>
<li><p><a class="reference external" href="https://examples.dask.org/array.html">Array examples</a></p></li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[31]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">client</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="04_dataframe.html" class="btn btn-neutral float-right" title="Dask DataFrames" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="02_bag.html" class="btn btn-neutral float-left" title="Bag: Parallel Lists for semi-structured data" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Dask Developers

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>